{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./example_data.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember not to pull a .show() at the end of this line.  .show() tells lazy spark to perform the task, but it outputs to the console.  \n",
    "# assigning it back into df would result in df being a nonetype.\n",
    "df = df.select(df.n.cast('float'), df.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|  15.0|    b|\n",
      "|  23.0|    c|\n",
      "|   6.0|    c|\n",
      "|   NaN|    c|\n",
      "|  26.0|    b|\n",
      "|  12.0|    b|\n",
      "|   8.0|    a|\n",
      "|  18.0|    c|\n",
      "|  14.0|    a|\n",
      "|  20.0|    c|\n",
      "|  22.0|    a|\n",
      "|  21.0|    a|\n",
      "|   1.0|    c|\n",
      "|   0.0|    a|\n",
      "|  17.0|    b|\n",
      "|   2.0|    a|\n",
      "|   7.0|    a|\n",
      "|  16.0|    b|\n",
      "|  24.0|    b|\n",
      "|  10.0|    a|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\\\n",
    "      .withColumnRenamed('n', 'number')\\\n",
    "     .withColumnRenamed('g', 'group')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df\\\n",
    "      .withColumnRenamed('n', 'number')\\\n",
    "     .withColumnRenamed('g', 'group'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------+\n",
      "|number|group|n_is_even|\n",
      "+------+-----+---------+\n",
      "|  15.0|    b|    false|\n",
      "|  23.0|    c|    false|\n",
      "|   6.0|    c|     true|\n",
      "|   NaN|    c|    false|\n",
      "|  26.0|    b|     true|\n",
      "|  12.0|    b|     true|\n",
      "|   8.0|    a|     true|\n",
      "|  18.0|    c|     true|\n",
      "|  14.0|    a|     true|\n",
      "|  20.0|    c|     true|\n",
      "|  22.0|    a|     true|\n",
      "|  21.0|    a|    false|\n",
      "|   1.0|    c|    false|\n",
      "|   0.0|    a|     true|\n",
      "|  17.0|    b|    false|\n",
      "|   2.0|    a|     true|\n",
      "|   7.0|    a|    false|\n",
      "|  16.0|    b|     true|\n",
      "|  24.0|    b|     true|\n",
      "|  10.0|    a|     true|\n",
      "+------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performing a transformation on a column and broadcasting it as a new column:\n",
    "df.withColumn('n_is_even', df.number % 2 == 0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------+\n",
      "|number|group|n_is_even|\n",
      "+------+-----+---------+\n",
      "|  15.0|    b|    false|\n",
      "|  23.0|    c|    false|\n",
      "|   6.0|    c|     true|\n",
      "|   NaN|    c|    false|\n",
      "|  26.0|    b|     true|\n",
      "|  12.0|    b|     true|\n",
      "|   8.0|    a|     true|\n",
      "|  18.0|    c|     true|\n",
      "|  14.0|    a|     true|\n",
      "|  20.0|    c|     true|\n",
      "|  22.0|    a|     true|\n",
      "|  21.0|    a|    false|\n",
      "|   1.0|    c|    false|\n",
      "|   0.0|    a|     true|\n",
      "|  17.0|    b|    false|\n",
      "|   2.0|    a|     true|\n",
      "|   7.0|    a|    false|\n",
      "|  16.0|    b|     true|\n",
      "|  24.0|    b|     true|\n",
      "|  10.0|    a|     true|\n",
      "+------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# alternatively:\n",
    "from pyspark.sql.functions import col, expr\n",
    "df.withColumn('n_is_even', col('number') % 2 == 0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|(number + 1)|((number % 2) = 0)|\n",
      "+------------+------------------+\n",
      "|        16.0|             false|\n",
      "|        24.0|             false|\n",
      "|         7.0|              true|\n",
      "|         NaN|             false|\n",
      "|        27.0|              true|\n",
      "|        13.0|              true|\n",
      "|         9.0|              true|\n",
      "|        19.0|              true|\n",
      "|        15.0|              true|\n",
      "|        21.0|              true|\n",
      "|        23.0|              true|\n",
      "|        22.0|             false|\n",
      "|         2.0|             false|\n",
      "|         1.0|              true|\n",
      "|        18.0|             false|\n",
      "|         3.0|              true|\n",
      "|         8.0|             false|\n",
      "|        17.0|              true|\n",
      "|        25.0|              true|\n",
      "|        11.0|              true|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# doing it by using a string literal:\n",
    "df.selectExpr('number + 1', 'number % 2 = 0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------+\n",
      "|number|group|number_is_even|\n",
      "+------+-----+--------------+\n",
      "|  15.0|    b|         false|\n",
      "|  23.0|    c|         false|\n",
      "|   6.0|    c|          true|\n",
      "|   NaN|    c|         false|\n",
      "|  26.0|    b|          true|\n",
      "|  12.0|    b|          true|\n",
      "|   8.0|    a|          true|\n",
      "|  18.0|    c|          true|\n",
      "|  14.0|    a|          true|\n",
      "|  20.0|    c|          true|\n",
      "|  22.0|    a|          true|\n",
      "|  21.0|    a|         false|\n",
      "|   1.0|    c|         false|\n",
      "|   0.0|    a|          true|\n",
      "|  17.0|    b|         false|\n",
      "|   2.0|    a|          true|\n",
      "|   7.0|    a|         false|\n",
      "|  16.0|    b|          true|\n",
      "|  24.0|    b|          true|\n",
      "|  10.0|    a|          true|\n",
      "+------+-----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# another tactic for column creation:\n",
    "df.selectExpr('*', 'number % 2 = 0 as number_is_even').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: remember, spark dataframes are immutable.\n",
    "# you cannot make a new column as in pandas like df['new_col'] and broadcast a new column that way\n",
    "# because you cannot merely adapt your current dataframe.\n",
    "# you can only perform transformations and output a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|  15.0|\n",
      "|  23.0|\n",
      "|   6.0|\n",
      "|   NaN|\n",
      "|  26.0|\n",
      "|  12.0|\n",
      "|   8.0|\n",
      "|  18.0|\n",
      "|  14.0|\n",
      "|  20.0|\n",
      "|  22.0|\n",
      "|  21.0|\n",
      "|   1.0|\n",
      "|   0.0|\n",
      "|  17.0|\n",
      "|   2.0|\n",
      "|   7.0|\n",
      "|  16.0|\n",
      "|  24.0|\n",
      "|  10.0|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop a column: \n",
    "f.drop('group').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|   6.0|    c|\n",
      "|   8.0|    a|\n",
      "|   1.0|    c|\n",
      "|   0.0|    a|\n",
      "|   2.0|    a|\n",
      "|   7.0|    a|\n",
      "|   4.0|    c|\n",
      "|   5.0|    a|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# where clause:\n",
    "df.where(df.number < 10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|   6.0|    c|\n",
      "|   8.0|    a|\n",
      "|   1.0|    c|\n",
      "|   0.0|    a|\n",
      "|   2.0|    a|\n",
      "|   7.0|    a|\n",
      "|   4.0|    c|\n",
      "|   5.0|    a|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# alternatively:\n",
    "df.where('number < 10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|   6.0|    c|\n",
      "|   8.0|    a|\n",
      "|   7.0|    a|\n",
      "|   5.0|    a|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where('number < 10').where(col('number') > 4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|   6.0|    c|\n",
      "|   8.0|    a|\n",
      "|   7.0|    a|\n",
      "|  10.0|    a|\n",
      "|   4.0|    c|\n",
      "|   5.0|    a|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.number.between(4, 10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|  23.0|    c|\n",
      "|   NaN|    c|\n",
      "|  18.0|    c|\n",
      "|  20.0|    c|\n",
      "|  27.0|    c|\n",
      "|  19.0|    c|\n",
      "|  29.0|    c|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter method:\n",
    "df.filter(df.group == 'c').filter(df.number > 10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|  23.0|    c|\n",
      "|   6.0|    c|\n",
      "|  12.0|    b|\n",
      "|  18.0|    c|\n",
      "|  14.0|    a|\n",
      "|  20.0|    c|\n",
      "|  22.0|    a|\n",
      "|  17.0|    b|\n",
      "|   7.0|    a|\n",
      "|  27.0|    c|\n",
      "|  19.0|    c|\n",
      "|  13.0|    b|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take a sample of your dataframe:\n",
    "df.sample(0.5).show()\n",
    "\n",
    "# we will elaborate on this later to do a train/test split with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|   1.0|    c|\n",
      "|   4.0|    c|\n",
      "|   6.0|    c|\n",
      "|  18.0|    c|\n",
      "|  19.0|    c|\n",
      "|  20.0|    c|\n",
      "|  23.0|    c|\n",
      "|  27.0|    c|\n",
      "|  29.0|    c|\n",
      "|   NaN|    c|\n",
      "|  12.0|    b|\n",
      "|  13.0|    b|\n",
      "|  15.0|    b|\n",
      "|  16.0|    b|\n",
      "|  17.0|    b|\n",
      "|  24.0|    b|\n",
      "|  25.0|    b|\n",
      "|  26.0|    b|\n",
      "|   0.0|    a|\n",
      "|   2.0|    a|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets move on to some potentially more expensive operations.\n",
    "# so far everything we have done has been something can be done row by row.  \n",
    "# Let's attempt some operations that require full breadth of the data\n",
    "\n",
    "df.orderBy(df.group.desc(), df.number).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|   NaN|    c|\n",
      "|  29.0|    c|\n",
      "|  27.0|    c|\n",
      "|  23.0|    c|\n",
      "|  20.0|    c|\n",
      "|  19.0|    c|\n",
      "|  18.0|    c|\n",
      "|   6.0|    c|\n",
      "|   4.0|    c|\n",
      "|   1.0|    c|\n",
      "|  26.0|    b|\n",
      "|  25.0|    b|\n",
      "|  24.0|    b|\n",
      "|  17.0|    b|\n",
      "|  16.0|    b|\n",
      "|  15.0|    b|\n",
      "|  13.0|    b|\n",
      "|  12.0|    b|\n",
      "|   NaN|    a|\n",
      "|  28.0|    a|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "df.orderBy(df.group.desc(), desc('number')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|   1.0|    c|\n",
      "|   4.0|    c|\n",
      "|   6.0|    c|\n",
      "|  18.0|    c|\n",
      "|  19.0|    c|\n",
      "|  20.0|    c|\n",
      "|  23.0|    c|\n",
      "|  27.0|    c|\n",
      "|  29.0|    c|\n",
      "|   NaN|    c|\n",
      "|  12.0|    b|\n",
      "|  13.0|    b|\n",
      "|  15.0|    b|\n",
      "|  16.0|    b|\n",
      "|  17.0|    b|\n",
      "|  24.0|    b|\n",
      "|  25.0|    b|\n",
      "|  26.0|    b|\n",
      "|   0.0|    a|\n",
      "|   2.0|    a|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This doesn't seem to be working at the moment here, but there are ways to arrange the nulls in spark.\n",
    "df.orderBy(df.group.desc(), df.number.asc_nulls_last()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missed this one, check back later. df.sort('number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|  15.0|    b|\n",
      "|  23.0|    c|\n",
      "|   6.0|    c|\n",
      "|   NaN|    c|\n",
      "|  26.0|    b|\n",
      "|  12.0|    b|\n",
      "|   8.0|    D|\n",
      "|  18.0|    c|\n",
      "|  14.0|    D|\n",
      "|  20.0|    c|\n",
      "|  22.0|    D|\n",
      "|  21.0|    D|\n",
      "|   1.0|    c|\n",
      "|   0.0|    D|\n",
      "|  17.0|    b|\n",
      "|   2.0|    D|\n",
      "|   7.0|    D|\n",
      "|  16.0|    b|\n",
      "|  24.0|    b|\n",
      "|  10.0|    D|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.replace('a', 'D').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|  15.0|    B|\n",
      "|  23.0|    c|\n",
      "|   6.0|    c|\n",
      "|   NaN|    c|\n",
      "|  26.0|    B|\n",
      "|  12.0|    B|\n",
      "|   8.0|    A|\n",
      "|  18.0|    c|\n",
      "|  14.0|    A|\n",
      "|  20.0|    c|\n",
      "|  22.0|    A|\n",
      "|  21.0|    A|\n",
      "|   1.0|    c|\n",
      "|   0.0|    A|\n",
      "|  17.0|    B|\n",
      "|   2.0|    A|\n",
      "|   7.0|    A|\n",
      "|  16.0|    B|\n",
      "|  24.0|    B|\n",
      "|  10.0|    A|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replacements need to be of the same type to be performed.\n",
    "df.replace(['a', 'b'], ['A', 'B'], ['group']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|  15.0|    b|\n",
      "|  23.0|    c|\n",
      "|   6.0|    c|\n",
      "|  26.0|    b|\n",
      "|  12.0|    b|\n",
      "|   8.0|    a|\n",
      "|  18.0|    c|\n",
      "|  14.0|    a|\n",
      "|  20.0|    c|\n",
      "|  22.0|    a|\n",
      "|  21.0|    a|\n",
      "|   1.0|    c|\n",
      "|   0.0|    a|\n",
      "|  17.0|    b|\n",
      "|   2.0|    a|\n",
      "|   7.0|    a|\n",
      "|  16.0|    b|\n",
      "|  24.0|    b|\n",
      "|  10.0|    a|\n",
      "|   4.0|    c|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(), df.na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|  15.0|    b|\n",
      "|  23.0|    c|\n",
      "|   6.0|    c|\n",
      "|   0.0|    c|\n",
      "|  26.0|    b|\n",
      "|  12.0|    b|\n",
      "|   8.0|    a|\n",
      "|  18.0|    c|\n",
      "|  14.0|    a|\n",
      "|  20.0|    c|\n",
      "|  22.0|    a|\n",
      "|  21.0|    a|\n",
      "|   1.0|    c|\n",
      "|   0.0|    a|\n",
      "|  17.0|    b|\n",
      "|   2.0|    a|\n",
      "|   7.0|    a|\n",
      "|  16.0|    b|\n",
      "|  24.0|    b|\n",
      "|  10.0|    a|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|number|group|\n",
      "+------+-----+\n",
      "|  15.0|    b|\n",
      "|  23.0|    c|\n",
      "|   6.0|    c|\n",
      "|   0.0|    c|\n",
      "|  26.0|    b|\n",
      "|  12.0|    b|\n",
      "|   8.0|    a|\n",
      "|  18.0|    c|\n",
      "|  14.0|    a|\n",
      "|  20.0|    c|\n",
      "|  22.0|    a|\n",
      "|  21.0|    a|\n",
      "|   1.0|    c|\n",
      "|   0.0|    a|\n",
      "|  17.0|    b|\n",
      "|   2.0|    a|\n",
      "|   7.0|    a|\n",
      "|  16.0|    b|\n",
      "|  24.0|    b|\n",
      "|  10.0|    a|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(0, ['number']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the nas with the average value of the column:\n",
    "\n",
    "row = df.na.drop().agg(expr('avg(number)')).first()\n",
    "the_average = row['avg(number)']\n",
    "type(the_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|   number|group|\n",
      "+---------+-----+\n",
      "|      0.0|    a|\n",
      "|      1.0|    c|\n",
      "|      2.0|    a|\n",
      "|      4.0|    c|\n",
      "|      5.0|    a|\n",
      "|      6.0|    c|\n",
      "|      7.0|    a|\n",
      "|      8.0|    a|\n",
      "|     10.0|    a|\n",
      "|     11.0|    a|\n",
      "|     12.0|    b|\n",
      "|     13.0|    b|\n",
      "|     14.0|    a|\n",
      "|     15.0|    b|\n",
      "|15.107142|    c|\n",
      "|15.107142|    a|\n",
      "|     16.0|    b|\n",
      "|     17.0|    b|\n",
      "|     18.0|    c|\n",
      "|     19.0|    c|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(the_average, ['number']).sort('number').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(row): <class 'pyspark.sql.types.Row'>\n",
      "type(row.group): <class 'str'>\n",
      "row.group: b\n",
      "-------\n",
      "type(row): <class 'pyspark.sql.types.Row'>\n",
      "type(row.group): <class 'str'>\n",
      "row.group: c\n",
      "-------\n",
      "type(row): <class 'pyspark.sql.types.Row'>\n",
      "type(row.group): <class 'str'>\n",
      "row.group: c\n",
      "-------\n",
      "type(row): <class 'pyspark.sql.types.Row'>\n",
      "type(row.group): <class 'str'>\n",
      "row.group: c\n",
      "-------\n",
      "type(row): <class 'pyspark.sql.types.Row'>\n",
      "type(row.group): <class 'str'>\n",
      "row.group: b\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for row in df.head(5):\n",
    "    print('type(row): {}'.format(type(row)))\n",
    "    print('type(row.group): {}'.format(type(row.group)))\n",
    "    print('row.group: {}'.format(row.group))\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you do this:\n",
    "# from pyspark.sql.functions import *\n",
    "# this wont work:\n",
    "# sum([1,2,3,4])\n",
    "# because you have overwritten the conventional python built-in sum function with the pysprak.sql sum function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.csv('./sa311/case.csv', header=True, inferSchema=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+\n",
      "|format_string(%010d, council_district)|\n",
      "+--------------------------------------+\n",
      "|                            0000000005|\n",
      "|                            0000000003|\n",
      "|                            0000000003|\n",
      "|                            0000000003|\n",
      "|                            0000000007|\n",
      "|                            0000000007|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "|                            0000000004|\n",
      "+--------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remember string formatting?\n",
    "# remember padding?\n",
    "# dead memes remember.\n",
    "df.select(format_string('%010d', df.council_district)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so this is a column:\n",
    "type(format_string('%010d', df.council_district))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can assign it!:\n",
    "formatted_district = format_string('%010d', df.council_district)\n",
    "## oops missed the other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|request_address                         |\n",
      "+----------------------------------------+\n",
      "|2315  EL PASO ST, San Antonio, 78207    |\n",
      "|2215  GOLIAD RD, San Antonio, 78223     |\n",
      "|102  PALFREY ST W, San Antonio, 78223   |\n",
      "|114  LA GARDE ST, San Antonio, 78223    |\n",
      "|734  CLEARVIEW DR, San Antonio, 78228   |\n",
      "|BANDERA RD and BRESNAHAN                |\n",
      "|10133  FIGARO CANYON, San Antonio, 78251|\n",
      "|10133  FIGARO CANYON, San Antonio, 78251|\n",
      "|10133  FIGARO CANYON, San Antonio, 78251|\n",
      "|10133  FIGARO CANYON, San Antonio, 78251|\n",
      "|10133  FIGARO CANYON, San Antonio, 78251|\n",
      "|10133  FIGARO CANYON, San Antonio, 78251|\n",
      "|10129  BOXING PASS, San Antonio, 78251  |\n",
      "|10129  BOXING PASS, San Antonio, 78251  |\n",
      "|10129  BOXING PASS, San Antonio, 78251  |\n",
      "|834  BARREL POINT, San Antonio, 78251   |\n",
      "|834  BARREL POINT, San Antonio, 78251   |\n",
      "|834  BARREL POINT, San Antonio, 78251   |\n",
      "|834  BARREL POINT, San Antonio, 78251   |\n",
      "|834  BARREL POINT, San Antonio, 78251   |\n",
      "+----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\\\n",
    " .select('request_address')\\\n",
    " .show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|upper(request_address)                  |\n",
      "+----------------------------------------+\n",
      "|2315  EL PASO ST, SAN ANTONIO, 78207    |\n",
      "|2215  GOLIAD RD, SAN ANTONIO, 78223     |\n",
      "|102  PALFREY ST W, SAN ANTONIO, 78223   |\n",
      "|114  LA GARDE ST, SAN ANTONIO, 78223    |\n",
      "|734  CLEARVIEW DR, SAN ANTONIO, 78228   |\n",
      "|BANDERA RD AND BRESNAHAN                |\n",
      "|10133  FIGARO CANYON, SAN ANTONIO, 78251|\n",
      "|10133  FIGARO CANYON, SAN ANTONIO, 78251|\n",
      "|10133  FIGARO CANYON, SAN ANTONIO, 78251|\n",
      "|10133  FIGARO CANYON, SAN ANTONIO, 78251|\n",
      "|10133  FIGARO CANYON, SAN ANTONIO, 78251|\n",
      "|10133  FIGARO CANYON, SAN ANTONIO, 78251|\n",
      "|10129  BOXING PASS, SAN ANTONIO, 78251  |\n",
      "|10129  BOXING PASS, SAN ANTONIO, 78251  |\n",
      "|10129  BOXING PASS, SAN ANTONIO, 78251  |\n",
      "|834  BARREL POINT, SAN ANTONIO, 78251   |\n",
      "|834  BARREL POINT, SAN ANTONIO, 78251   |\n",
      "|834  BARREL POINT, SAN ANTONIO, 78251   |\n",
      "|834  BARREL POINT, SAN ANTONIO, 78251   |\n",
      "|834  BARREL POINT, SAN ANTONIO, 78251   |\n",
      "+----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\\\n",
    " .select(upper(df.request_address))\\\n",
    " .show(truncate=False))# if you just pass 'request_address' in this one its gonna break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|substring(request_address, 0, 20)|\n",
      "+---------------------------------+\n",
      "|2315  EL PASO ST, Sa             |\n",
      "|2215  GOLIAD RD, San             |\n",
      "|102  PALFREY ST W, S             |\n",
      "+---------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# substrings: first 20 chars of each address: \n",
    "# note substring is starting character and then number charcters to take.  Start on index 0, go for 20 chars.\n",
    "(df\\\n",
    " .select(substring(df.request_address, 0, 20))\\\n",
    " .show(3, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|zip  |\n",
      "+-----+\n",
      "|78207|\n",
      "|78223|\n",
      "|78223|\n",
      "|78223|\n",
      "|78228|\n",
      "|     |\n",
      "|78251|\n",
      "|78251|\n",
      "|78251|\n",
      "|78251|\n",
      "+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\\\n",
    ".select(regexp_extract(df.request_address, r'\\d+$',0).alias('zip'))\\\n",
    ".show(10, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+-----------+-----+\n",
      "|request_address                         |city       |zip  |\n",
      "+----------------------------------------+-----------+-----+\n",
      "|2315  EL PASO ST, San Antonio, 78207    |San Antonio|78207|\n",
      "|2215  GOLIAD RD, San Antonio, 78223     |San Antonio|78223|\n",
      "|102  PALFREY ST W, San Antonio, 78223   |San Antonio|78223|\n",
      "|114  LA GARDE ST, San Antonio, 78223    |San Antonio|78223|\n",
      "|734  CLEARVIEW DR, San Antonio, 78228   |San Antonio|78228|\n",
      "|BANDERA RD and BRESNAHAN                |           |     |\n",
      "|10133  FIGARO CANYON, San Antonio, 78251|San Antonio|78251|\n",
      "|10133  FIGARO CANYON, San Antonio, 78251|San Antonio|78251|\n",
      "|10133  FIGARO CANYON, San Antonio, 78251|San Antonio|78251|\n",
      "|10133  FIGARO CANYON, San Antonio, 78251|San Antonio|78251|\n",
      "+----------------------------------------+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "address_re = r'^.+,\\s(.+),\\s+(\\d+)$'\n",
    "\n",
    "(df\n",
    ".select(df.request_address, \n",
    "        regexp_extract(df.request_address, address_re, 1).alias('city'), \n",
    "        regexp_extract(df.request_address, address_re, 2).alias('zip')).show(10, truncate=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: integer (nullable = true)\n",
      " |-- case_opened_date: string (nullable = true)\n",
      " |-- case_closed_date: string (nullable = true)\n",
      " |-- SLA_due_date: string (nullable = true)\n",
      " |-- case_late: string (nullable = true)\n",
      " |-- num_days_late: double (nullable = true)\n",
      " |-- case_closed: string (nullable = true)\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- service_request_type: string (nullable = true)\n",
      " |-- SLA_days: double (nullable = true)\n",
      " |-- case_status: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- request_address: string (nullable = true)\n",
      " |-- council_district: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|case_opened_date|\n",
      "+----------------+\n",
      "|     1/1/18 0:42|\n",
      "|     1/1/18 0:46|\n",
      "|     1/1/18 0:48|\n",
      "|     1/1/18 1:29|\n",
      "|     1/1/18 1:34|\n",
      "|     1/1/18 6:28|\n",
      "|     1/1/18 6:57|\n",
      "|     1/1/18 6:58|\n",
      "|     1/1/18 6:58|\n",
      "|     1/1/18 6:59|\n",
      "|     1/1/18 7:00|\n",
      "|     1/1/18 7:02|\n",
      "|     1/1/18 7:02|\n",
      "|     1/1/18 7:03|\n",
      "|     1/1/18 7:04|\n",
      "|     1/1/18 7:04|\n",
      "|     1/1/18 7:05|\n",
      "|     1/1/18 7:06|\n",
      "|     1/1/18 7:06|\n",
      "|     1/1/18 7:07|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.case_opened_date).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|case_opened_date|\n",
      "+----------------+\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's fix the columns that are represented as strings that should not be that way.\n",
    "(df.select(df.case_opened_date.cast('timestamp'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_jvm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-55b5560cd469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m (df\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcase_opened_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'M/d/y H:mm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m .show(10))\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mto_timestamp\u001b[0;34m(col, format)\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_jvm'"
     ]
    }
   ],
   "source": [
    "(df\n",
    ".select(to_timestamp(df.case_opened_date, 'M/d/y H:mm').alias('ts'))\n",
    ".show(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back and get this stuff.  Spent too much time trying to troubleshoot those nulls here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: integer (nullable = true)\n",
      " |-- case_opened_date: string (nullable = true)\n",
      " |-- case_closed_date: string (nullable = true)\n",
      " |-- SLA_due_date: string (nullable = true)\n",
      " |-- case_late: string (nullable = true)\n",
      " |-- num_days_late: double (nullable = true)\n",
      " |-- case_closed: string (nullable = true)\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- service_request_type: string (nullable = true)\n",
      " |-- SLA_days: double (nullable = true)\n",
      " |-- case_status: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- request_address: string (nullable = true)\n",
      " |-- council_district: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|      num_days_late|\n",
      "+-------------------+\n",
      "| -998.5087616000001|\n",
      "|-2.0126041669999997|\n",
      "|       -3.022337963|\n",
      "|       -15.01148148|\n",
      "|0.37216435200000003|\n",
      "|       -29.74398148|\n",
      "|       -14.70673611|\n",
      "|       -14.70662037|\n",
      "|       -14.70662037|\n",
      "|       -14.70649306|\n",
      "|       -14.70649306|\n",
      "|       -14.70636574|\n",
      "|          -14.70625|\n",
      "|       -14.70636574|\n",
      "|       -14.70623843|\n",
      "|-14.705891199999998|\n",
      "|       -14.70600694|\n",
      "|       -14.70576389|\n",
      "|       -14.70576389|\n",
      "|       -14.70564815|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.num_days_late).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|CASE WHEN (num_days_late >= 0) THEN num_days_late ELSE 0 END|\n",
      "+------------------------------------------------------------+\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                         0.37216435200000003|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "|                                                         0.0|\n",
      "+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_col = when(df.num_days_late >= 0, df.num_days_late).otherwise(0)\n",
    "\n",
    "(df\n",
    ".select(df.num_days_late)\n",
    ".select(my_col)\n",
    ".show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------------+\n",
      "|case_closed|case_late|      num_days_late|\n",
      "+-----------+---------+-------------------+\n",
      "|       true|     true|0.37216435200000003|\n",
      "|       true|     true|         0.03150463|\n",
      "|       true|     true|        80.74537037|\n",
      "|       true|     true|0.38280092600000004|\n",
      "|       true|     true|        0.376655093|\n",
      "|       true|     true|        46.41153935|\n",
      "|       true|     true|        0.048368056|\n",
      "|       true|     true|         36.1630787|\n",
      "|       true|     true|        25.36005787|\n",
      "|       true|     true| 1.8262268519999998|\n",
      "|       true|     true|         46.3819213|\n",
      "|       true|     true|        46.38175926|\n",
      "|       true|     true|        72.39403935|\n",
      "|       true|     true| 113.73300929999999|\n",
      "|       true|     true|        79.13157407|\n",
      "|       true|     true|        3.450983796|\n",
      "|       true|     true|        73.16055556|\n",
      "|       true|     true|        1.339675926|\n",
      "|       true|     true|        68.02585648|\n",
      "|       true|     true|        72.37243056|\n",
      "+-----------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    ".select(df.case_closed, df.case_late, df.num_days_late)\n",
    ".select((df.case_closed =='YES').alias('case_closed'), \n",
    "       (df.case_late =='YES').alias('case_late'), \n",
    "       df.num_days_late)\n",
    ".filter(col('case_late'))\n",
    ".show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------------+\n",
      "|case_closed|case_late|      num_days_late|\n",
      "+-----------+---------+-------------------+\n",
      "|       true|     true|0.37216435200000003|\n",
      "|       true|     true|         0.03150463|\n",
      "|       true|     true|        80.74537037|\n",
      "|       true|     true|0.38280092600000004|\n",
      "|       true|     true|        0.376655093|\n",
      "|       true|     true|        46.41153935|\n",
      "|       true|     true|        0.048368056|\n",
      "|       true|     true|         36.1630787|\n",
      "|       true|     true|        25.36005787|\n",
      "|       true|     true| 1.8262268519999998|\n",
      "|       true|     true|         46.3819213|\n",
      "|       true|     true|        46.38175926|\n",
      "|       true|     true|        72.39403935|\n",
      "|       true|     true| 113.73300929999999|\n",
      "|       true|     true|        79.13157407|\n",
      "|       true|     true|        3.450983796|\n",
      "|       true|     true|        73.16055556|\n",
      "|       true|     true|        1.339675926|\n",
      "|       true|     true|        68.02585648|\n",
      "|       true|     true|        72.37243056|\n",
      "+-----------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    ".select(df.case_closed, df.case_late, df.num_days_late)\n",
    ".withColumn('case_closed', df.case_closed == 'YES')\n",
    " .withColumn('case_late', df.case_late == 'YES')\n",
    " .where(col('case_late'))\n",
    " .where(col('case_closed'))\n",
    ".show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------------+\n",
      "|case_closed|case_late|      num_days_late|\n",
      "+-----------+---------+-------------------+\n",
      "|       true|    false| -998.5087616000001|\n",
      "|       true|    false|-2.0126041669999997|\n",
      "|       true|    false|       -3.022337963|\n",
      "|       true|    false|       -15.01148148|\n",
      "|       true|     true|0.37216435200000003|\n",
      "|       true|    false|       -29.74398148|\n",
      "|       true|    false|       -14.70673611|\n",
      "|       true|    false|       -14.70662037|\n",
      "|       true|    false|       -14.70662037|\n",
      "|       true|    false|       -14.70649306|\n",
      "|       true|    false|       -14.70649306|\n",
      "|       true|    false|       -14.70636574|\n",
      "|       true|    false|          -14.70625|\n",
      "|       true|    false|       -14.70636574|\n",
      "|       true|    false|       -14.70623843|\n",
      "|       true|    false|-14.705891199999998|\n",
      "|       true|    false|       -14.70600694|\n",
      "|       true|    false|       -14.70576389|\n",
      "|       true|    false|       -14.70576389|\n",
      "|       true|    false|       -14.70564815|\n",
      "+-----------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    ".select(df.case_closed, df.case_late, df.num_days_late)\n",
    ".withColumn('case_closed', df.case_closed == 'YES')\n",
    " .withColumn('case_late', df.case_late == 'YES')\n",
    " .filter(col('case_late') | col('case_closed'))\n",
    ".show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = (spark.read.csv('./users.csv', header=True, inferSchema=True))\n",
    "roles = (spark.read.csv('./roles.csv', header=True, inferSchema=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------------+-------+----+---------+\n",
      "|  id| name|            email|role_id|  id|     name|\n",
      "+----+-----+-----------------+-------+----+---------+\n",
      "|   5| jane| jane@example.com|   NULL|null|     null|\n",
      "|   6| mike| mike@example.com|   NULL|null|     null|\n",
      "|   1|  bob|  bob@example.com|      1|   1|    admin|\n",
      "|   3|sally|sally@example.com|      3|   3| reviewer|\n",
      "|   4| adam| adam@example.com|      3|   3| reviewer|\n",
      "|null| null|             null|   null|   4|commenter|\n",
      "|   2|  joe|  joe@example.com|      2|   2|   author|\n",
      "+----+-----+-----------------+-------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.join(roles, users.role_id == roles.id, 'outer').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------------+-------+----+--------+\n",
      "| id| name|            email|role_id|  id|    name|\n",
      "+---+-----+-----------------+-------+----+--------+\n",
      "|  1|  bob|  bob@example.com|      1|   1|   admin|\n",
      "|  2|  joe|  joe@example.com|      2|   2|  author|\n",
      "|  3|sally|sally@example.com|      3|   3|reviewer|\n",
      "|  4| adam| adam@example.com|      3|   3|reviewer|\n",
      "|  5| jane| jane@example.com|   NULL|null|    null|\n",
      "|  6| mike| mike@example.com|   NULL|null|    null|\n",
      "+---+-----+-----------------+-------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.join(roles, users.role_id == roles.id, 'left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------------+-------+---+---------+\n",
      "|  id| name|            email|role_id| id|     name|\n",
      "+----+-----+-----------------+-------+---+---------+\n",
      "|   1|  bob|  bob@example.com|      1|  1|    admin|\n",
      "|   2|  joe|  joe@example.com|      2|  2|   author|\n",
      "|   4| adam| adam@example.com|      3|  3| reviewer|\n",
      "|   3|sally|sally@example.com|      3|  3| reviewer|\n",
      "|null| null|             null|   null|  4|commenter|\n",
      "+----+-----+-----------------+-------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.join(roles, users.role_id == roles.id, 'right').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lots of weird join methods we can use here.  anti, semi, cross... play around with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------------+-------+\n",
      "| id|name|           email|role_id|\n",
      "+---+----+----------------+-------+\n",
      "|  5|jane|jane@example.com|   NULL|\n",
      "|  6|mike|mike@example.com|   NULL|\n",
      "+---+----+----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.join(roles, users.role_id == roles.id, 'left_anti').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------------+-------+---+---------+\n",
      "| id| name|            email|role_id| id|     name|\n",
      "+---+-----+-----------------+-------+---+---------+\n",
      "|  1|  bob|  bob@example.com|      1|  1|    admin|\n",
      "|  1|  bob|  bob@example.com|      1|  2|   author|\n",
      "|  1|  bob|  bob@example.com|      1|  3| reviewer|\n",
      "|  1|  bob|  bob@example.com|      1|  4|commenter|\n",
      "|  2|  joe|  joe@example.com|      2|  1|    admin|\n",
      "|  2|  joe|  joe@example.com|      2|  2|   author|\n",
      "|  2|  joe|  joe@example.com|      2|  3| reviewer|\n",
      "|  2|  joe|  joe@example.com|      2|  4|commenter|\n",
      "|  3|sally|sally@example.com|      3|  1|    admin|\n",
      "|  3|sally|sally@example.com|      3|  2|   author|\n",
      "|  3|sally|sally@example.com|      3|  3| reviewer|\n",
      "|  3|sally|sally@example.com|      3|  4|commenter|\n",
      "|  4| adam| adam@example.com|      3|  1|    admin|\n",
      "|  4| adam| adam@example.com|      3|  2|   author|\n",
      "|  4| adam| adam@example.com|      3|  3| reviewer|\n",
      "|  4| adam| adam@example.com|      3|  4|commenter|\n",
      "|  5| jane| jane@example.com|   NULL|  1|    admin|\n",
      "|  5| jane| jane@example.com|   NULL|  2|   author|\n",
      "|  5| jane| jane@example.com|   NULL|  3| reviewer|\n",
      "|  5| jane| jane@example.com|   NULL|  4|commenter|\n",
      "+---+-----+-----------------+-------+---+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.crossJoin(roles).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------------+-------+\n",
      "| id| name|            email|role_id|\n",
      "+---+-----+-----------------+-------+\n",
      "|  1|  bob|  bob@example.com|      1|\n",
      "|  2|  joe|  joe@example.com|      2|\n",
      "|  3|sally|sally@example.com|      3|\n",
      "|  4| adam| adam@example.com|      3|\n",
      "|  5| jane| jane@example.com|   NULL|\n",
      "|  6| mike| mike@example.com|   NULL|\n",
      "|  1|  bob|  bob@example.com|      1|\n",
      "|  2|  joe|  joe@example.com|      2|\n",
      "|  3|sally|sally@example.com|      3|\n",
      "|  4| adam| adam@example.com|      3|\n",
      "|  5| jane| jane@example.com|   NULL|\n",
      "|  6| mike| mike@example.com|   NULL|\n",
      "+---+-----+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unions work like they do in sql\n",
    "users.union(users).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([.6, .4], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = df.randomSplit([.6, .2, .2], seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504429"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can pull this with just pure ratios, just make sure your numbers are in floats\n",
    "train, test = df.randomSplit([3.0, 1.0], seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./example_data.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|   n|  g|\n",
      "+----+---+\n",
      "|15.0|  b|\n",
      "|23.0|  c|\n",
      "| 6.0|  c|\n",
      "| NaN|  c|\n",
      "|26.0|  b|\n",
      "|12.0|  b|\n",
      "| 8.0|  a|\n",
      "|18.0|  c|\n",
      "|14.0|  a|\n",
      "|20.0|  c|\n",
      "|22.0|  a|\n",
      "|21.0|  a|\n",
      "| 1.0|  c|\n",
      "| 0.0|  a|\n",
      "|17.0|  b|\n",
      "| 2.0|  a|\n",
      "| 7.0|  a|\n",
      "|16.0|  b|\n",
      "|24.0|  b|\n",
      "|10.0|  a|\n",
      "+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|   n|  g|\n",
      "+----+---+\n",
      "|15.0|  b|\n",
      "|23.0|  c|\n",
      "| 6.0|  c|\n",
      "| NaN|  c|\n",
      "|26.0|  b|\n",
      "|12.0|  b|\n",
      "| 8.0|  a|\n",
      "|18.0|  c|\n",
      "|14.0|  a|\n",
      "|20.0|  c|\n",
      "|22.0|  a|\n",
      "|21.0|  a|\n",
      "| 1.0|  c|\n",
      "| 0.0|  a|\n",
      "|17.0|  b|\n",
      "| 2.0|  a|\n",
      "| 7.0|  a|\n",
      "|16.0|  b|\n",
      "|24.0|  b|\n",
      "|10.0|  a|\n",
      "+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----+\n",
      "|summary|  n|   g|\n",
      "+-------+---+----+\n",
      "|  count| 30|  30|\n",
      "|   mean|NaN|null|\n",
      "| stddev|NaN|null|\n",
      "|    min|0.0|   a|\n",
      "|    max|NaN|   c|\n",
      "+-------+---+----+\n",
      "\n",
      "+--------------+\n",
      "|stddev_samp(n)|\n",
      "+--------------+\n",
      "|           NaN|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()\n",
    "\n",
    "df.agg(stddev(df.n)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|  g|count(n)|\n",
      "+---+--------+\n",
      "|  c|      10|\n",
      "|  b|       8|\n",
      "|  a|      12|\n",
      "+---+--------+\n",
      "\n",
      "+---+--------+\n",
      "|  g|count(n)|\n",
      "+---+--------+\n",
      "|  c|      10|\n",
      "|  b|       8|\n",
      "|  a|      12|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('g').agg(count(df.n)).show()\n",
    "df.groupBy('g').agg(expr('count(n)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OOPS\n",
    "# missed stuff\n",
    "# df.groupBy('g')\n",
    "# .agg(expr('count(n)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.csv('./sa311/case.csv', header=True, inferSchema=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+------+\n",
      "|case_late_case_closed|   NO|   YES|\n",
      "+---------------------+-----+------+\n",
      "|                  YES| 6525| 87978|\n",
      "|                   NO|11585|735616|\n",
      "+---------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    ".select('case_late', 'case_closed', 'num_days_late')\n",
    ".crosstab('case_late', 'case_closed')\n",
    ".show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+\n",
      "|case_late|                 NO|                YES|\n",
      "+---------+-------------------+-------------------+\n",
      "|      YES|  70.02952998931113| 22.111760411319253|\n",
      "|       NO|-53.775669814418364|-58.571301683913845|\n",
      "+---------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets try making this crosstab manually using pivot tables\n",
    "(df\n",
    ".select('case_late', 'case_closed', 'num_days_late')\n",
    " .groupBy('case_late') # rows\n",
    " .pivot('case_closed') #columns\n",
    " .agg(avg(col('num_days_late'))) # values\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
